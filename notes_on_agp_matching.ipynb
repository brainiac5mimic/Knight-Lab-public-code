{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Things to do\n",
    "    Update unit test file\n",
    "    Do more tests for stable marage\n",
    "    Revise function headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import getopt, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import qiime2\n",
    "import time\n",
    "\n",
    "from qiime2 import Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a match_controls_forPlot.py file to make the plots below. It makes changes to file data_plot.csv created below. match_controls_forPlot.py is the same as match_controls.py except for the ability to change data_plot.csv. The only time that should be affected is load since the dataset and conditions are new things that are stored at that phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file names for match, null, keep, case, and control indicate the conditions. Files with no conditions are the base line. r means range of exeptable samples. L, M, S usually mean Large, Medium, and Small respectivly except when they follow a number. In the case of L a number in front of it indicate how many lines the file is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python match_controls.py --verbose --inputdata sk_files/sk_hc_merged.txt --nullvalues sk_files/skit_nullvalues.txt --case sk_files/skit_case.txt --control sk_files/skit_control.txt --match sk_files/skit_match.txt --output outputFiles/sk_output_testKeep.csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python match_controls.py --inputdata emp_files/emp_qiime_mapping_release1.tsv --output outputFiles/emp_output.csv --keep emp_files/emp_keep.txt  --control emp_files/emp_control.txt --case  emp_files/emp_case.txt --match emp_files/emp_match.txt --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python match_controls.py --inputdata psych_files/psych_bins_saliva.txt --output outputFiles/psych_output_all.csv --keep psych_files/psych_bins_saliva_filter.txt --control psych_files/psych_bins_saliva_control.txt --case psych_files/psych_bins_saliva_case.txt --match psych_files/psych_bins_saliva_match.txt --nullvalues psych_files/psych_bins_saliva_null_values.txt --verbose\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python _match_controls.py --inputdata unitTest_files/test_data.txt --output outputFiles/unitTest_all.csv --keep unitTest_files/test_keep.txt --control unitTest_files/test_control.txt --case unitTest_files/test_case.txt --match unitTest_files/test_match.txt --nullvalues unitTest_files/test_nulls.txt --verbose --csvdata_keep unitTest_files/unit_keep.csv --csvdata_case_control unitTest_files/unit_control.csv  --csvdata_filter unitTest_files/unit_filtered.csv  --csvdata_match unitTest_files/unit_match.csv \n",
    "\n",
    "--inputdata \n",
    "unitTest_files/test_data.txt \n",
    "--output \n",
    "outputFiles/unitTest_all.csv \n",
    "\n",
    "--keep \n",
    "unitTest_files/test_keep.txt \n",
    "--control \n",
    "unitTest_files/test_control.txt \n",
    "--case \n",
    "unitTest_files/test_case.txt \n",
    "--nullvalues \n",
    "unitTest_files/test_nulls.txt\n",
    "--match \n",
    "unitTest_files/test_match.txt \n",
    "\n",
    "--csvdata_keep \n",
    "unitTest_files/unit_keep.csv \n",
    "--csvdata_case_control \n",
    "unitTest_files/unit_control.csv  \n",
    "--csvdata_filter \n",
    "unitTest_files/unit_filtered.csv  \n",
    "--csvdata_match \n",
    "unitTest_files/unit_match.csv "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "format of match\n",
    "each line is tab seperated\n",
    "the first element is the type of match: range or exact\n",
    "    range matches samples if the numerical values compared are with in some other number of eachother\n",
    "        this is only to be used with numerical values\n",
    "    exact matches samples if the values compared are exactly the same\n",
    "        this can be used for strings and numbers\n",
    "the second element is the column to compare values of for the case and control samples\n",
    "the third element is the range number if the match type is range\n",
    "    this determines how far away a sample can be from another sample for the given column to be matched\n",
    "    there is not third element if the match type is exact\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "compare series not tables \n",
    "clean up headers and parameters\n",
    "look into solving stable marraige bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unknown if     index_header_name = afterExclusion_MD.id_header\n",
    "is still usefull for merging\n",
    "\n",
    "must be in folder with input data to use it in load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stable marriage debugging\n",
    "not all samples are matched properly if two cases have same amount of matches and they overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def order_keys(dictionary):\n",
    "    '''\n",
    "    orders the keys of a dictionary so that they can be used properly as the freemen of stable marriage. In order greatest to least since pop is used to get least freeman and pop takes the right most entry. \n",
    "\n",
    "    Parameters\n",
    "    dictionary\n",
    "        dictionary of cases or controls with their matching controls or cases ordered \n",
    "        by rising abundance\n",
    "    \n",
    "    Return\n",
    "    keys_greatest_to_least: list\n",
    "        contains keys in order of greatest to least amount of samples they match to\n",
    "    '''\n",
    "    keys_greatest_to_least = []\n",
    "    for key in dictionary:\n",
    "        if keys_greatest_to_least == [] and len(dictionary[key])!=0:\n",
    "            keys_greatest_to_least.append(key)\n",
    "            continue\n",
    "        abundance_of_key_values = len(dictionary[key])\n",
    "        index = 0\n",
    "        for list_key in keys_greatest_to_least:\n",
    "            abundance_of_list_key_values = len(dictionary[list_key])\n",
    "            \n",
    "            if abundance_of_key_values > abundance_of_list_key_values:\n",
    "                keys_greatest_to_least.insert(index, key)\n",
    "                break\n",
    "            if abundance_of_key_values == abundance_of_list_key_values:\n",
    "                    if list_key >= key:\n",
    "                        keys_greatest_to_least.insert(index, key)\n",
    "                        break\n",
    "            index = index + 1\n",
    "        if index == len(keys_greatest_to_least):\n",
    "            keys_greatest_to_least.append(key)\n",
    "\n",
    "    return keys_greatest_to_least\n",
    "\n",
    "def stable_marriage(case_dictionary, pref_counts_cont, pref_counts_case):\n",
    "    #first make master copy\n",
    "    master_copy_of_case_dict = case_dictionary.copy()\n",
    "    #cut out keys in case_dictionary that have no possible matches\n",
    "    list_of_keys = []\n",
    "    for key in case_dictionary:\n",
    "        list_of_keys.append(key)\n",
    "    for key in list_of_keys:\n",
    "        if len(case_dictionary[key])==0:\n",
    "            case_dictionary.pop(key,None)\n",
    "    \n",
    "    free_keys = order_keys(case_dictionary)\n",
    "    for key in free_keys:\n",
    "        if pref_counts_case[key]==0:\n",
    "            case_dictionary.pop(key,None)\n",
    "            \n",
    "            \n",
    "    print(free_keys)\n",
    "    one_to_one_match_dictionary = {}\n",
    "    while free_keys :\n",
    "        key = free_keys.pop()\n",
    "        #print(key)\n",
    "        print(case_dictionary)\n",
    "        if case_dictionary[key]==[]:\n",
    "            continue\n",
    "        #get the highest ranked woman that has not yet been proposed to\n",
    "        entry = case_dictionary[key].pop()\n",
    "        #print(case_dictionary)\n",
    "                \n",
    "        if entry not in one_to_one_match_dictionary: \n",
    "            one_to_one_match_dictionary[entry] = key\n",
    "            #remove key to reorder but this my not be the best if a switch is needed later\n",
    "            if case_dictionary[key]==[]:\n",
    "                case_dictionary.pop(key,None)\n",
    "            for case_key in case_dictionary:\n",
    "                if entry in case_dictionary[case_key]:\n",
    "                    case_dictionary[case_key].remove(entry)\n",
    "                    if case_dictionary[case_key] == []:\n",
    "                        case_dictionary[case_key] = []\n",
    "            #reorder keys\n",
    "            free_keys = order_keys(case_dictionary)\n",
    "            print(\"match %s to %s\"%(entry,key))\n",
    "            \n",
    "        else:\n",
    "            print(\"switch needed for key %s and entry %s\"%(key,entry))\n",
    "            key_in_use = one_to_one_match_dictionary [entry]\n",
    "            if pref_counts_case[key] < pref_counts_case[key_in_use]:\n",
    "                one_to_one_match_dictionary[entry] = key\n",
    "                free_keys.append(key_in_use)\n",
    "            else:\n",
    "                free_keys.append(key)\n",
    "                \n",
    "    return one_to_one_match_dictionary\n",
    "\n",
    "def test_stable_marriage():\n",
    "    case_dictionary = {'14': ['15', '17'], '25': [], '19': ['20'], '21':[], '6': [], '9': ['10'], '3': [], '7': ['8'], \n",
    "                       '18': ['17'], '23': [], '16': ['13', '15'], '27': [], '11': ['12']}\n",
    "    control_match_count_dictionary = {'10': 1, '15': 2, '17': 2, '12': 1, '8': 1, '20': 1, '13': 1}\n",
    "    case_match_count_dictionary = {'23': 0, '6': 0, '14': 2, '21': 0, '16': 2, '11': 1, '19': 1, '9': 1, '27': 0, '7': 1,\n",
    "                                   '3': 0, '25': 0, '18': 1}\n",
    "\n",
    "    case_to_control_match = stable_marriage(case_dictionary, control_match_count_dictionary, case_match_count_dictionary)\n",
    "    test_output  = {'15': '16', '12': '11', '8': '7', '10': '9', '17': '18', '20': '19'}\n",
    "    if case_to_control_match != test_output:\n",
    "        print(\"stable marriage fails. \\nOutput should be {'15': '16', '12': '11', '8': '7', '10': '9', '17': '18', '20': '19'} \\nOutput was\")\n",
    "        print(case_to_control_match)\n",
    "        \n",
    "        return False\n",
    "    return True\n",
    "print(test_stable_marriage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unorderedDict = {'key_1':['a','d','b','e','c'], 'key_2':['a','f','g',],  'key_3':['f','e','e','c','a'], \n",
    "                      'key_4':['a', 'd']}\n",
    "test_frequencies = {'a':4,'b':1,'c':2,'d':2,'e':3, 'f':2 , 'g':1}\n",
    "for k in test_unorderedDict:\n",
    "    test_unorderedDict[k] = sorted(test_unorderedDict[k])\n",
    "    test_unorderedDict[k] = sorted(test_unorderedDict[k], key = lambda x:test_frequencies[x] ) \n",
    "#, key=lambda x: len (test_unorderedDict[x])\n",
    "  \n",
    "test_unorderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unorderedDictLen={'2':['a','b'], '1':['a'],  '3':['a','b','c'],  '5':['a','b','c','d','e'], '4':['a','b','c','d']}\n",
    "\n",
    "order = sorted(test_unorderedDictLen, key=lambda x: len(test_unorderedDictLen[x]), reverse=True)\n",
    "  \n",
    "order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old entry ordering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_to_return = dictionary.copy()\n",
    "    for key in dictionary_to_return:\n",
    "        unordered_array = dictionary_to_return[key]\n",
    "        if len(unordered_array) == 0:\n",
    "            continue\n",
    "        #ordered_array will store the elements linked to key in their proper order\n",
    "        ordered_array = []\n",
    "        count = 0\n",
    "        while count < len(unordered_array):\n",
    "            value = unordered_array[count]\n",
    "            index = 0 #this index is for going through when sorting\n",
    "            while index < len(ordered_array):\n",
    "                ordered_value = ordered_array[index]\n",
    "                if value_frequency[ordered_value] > value_frequency[value]:\n",
    "                    ordered_array.insert(index,value)\n",
    "                    break\n",
    "                if value_frequency[ordered_value] == value_frequency[value]:\n",
    "                    if ordered_value >= value:\n",
    "                        ordered_array.insert(index,value)\n",
    "                        break\n",
    "                index = index + 1\n",
    "            if index == len(ordered_array):\n",
    "                ordered_array.insert(index,value)\n",
    "\n",
    "            count = count + 1\n",
    "        #overrides the unordered array linked to key with its ordered array\n",
    "        dictionary_to_return[key] = ordered_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dictionary:\n",
    "        if keys_greatest_to_least == []:\n",
    "            keys_greatest_to_least.append(key)\n",
    "            continue\n",
    "        abundance_of_key_values = len(dictionary[key])\n",
    "        index = 0\n",
    "        for list_key in keys_greatest_to_least:\n",
    "            abundance_of_list_key_values = len(dictionary[list_key])\n",
    "            if abundance_of_key_values > abundance_of_list_key_values:\n",
    "                keys_greatest_to_least.insert(index, key)\n",
    "                break\n",
    "            if abundance_of_key_values == abundance_of_list_key_values:\n",
    "                    if list_key >= key:\n",
    "                        keys_greatest_to_least.insert(index, key)\n",
    "                        break\n",
    "            index = index + 1\n",
    "        if index == len(keys_greatest_to_least):\n",
    "            keys_greatest_to_least.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvdata_match = pd.read_csv('./unitTest_files/unit_output.csv', sep = '\\t' )\n",
    "csvdata_match['id'] = csvdata_match['id'].astype('object')\n",
    "#print( csvdata_match['id'] )\n",
    "csvdata_match = csvdata_match.set_index('id').astype('object')\n",
    "csvdata_match.index = csvdata_match.index.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_case_controlDF_and_afterExclutionMD(afterExclusion_MD, case_controlDF):\n",
    "    '''\n",
    "    Combines case_controlDF with afterExclution_MD and returns it as a metadata object\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    afterExclusion_MD : Metadata object\n",
    "        Metadata object with unwanted samples filtered out\n",
    "        \n",
    "    case_controlDF : dataframe\n",
    "        dataframe with one column named case_control. The indexs are the same as the indexs of afterExclution_MD  \n",
    "        values reflect if the index is a case, control, or Undefined\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Metadata(returnedMD) : Metadata object\n",
    "        Metadata object with unwanted samples filtered out and a case_control column that reflects if the index is \n",
    "        a case, control, or Undefined    \n",
    "    '''\n",
    "    #turns case_controlDF into a metadata object\n",
    "    case_controlMD = Metadata( case_controlDF)\n",
    "    \n",
    "    index_header_name = afterExclusion_MD.id_header\n",
    "    #merges afterExclution_MD and case_controlMD into one new metadata object\n",
    "    mergedMD = Metadata.merge(afterExclusion_MD, case_controlMD)\n",
    "\n",
    "    return mergedMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFrame = pd.DataFrame(columns=['dataset','conditions','load','keep','case_control','null_filter','match','total'])\n",
    "plotFrame.index.name = 'id'\n",
    "plotFrame.to_csv('data_plot.csv', sep = '\\t')\n",
    "#plotFrame = plotFrame.append(pd.Series( {'dataset':1, 'conditions':1, 'case_control':(1- 2), 'match':(2- 1), 'total':(2-1), 'null_filter':(2 - 1), 'keep':(2 - 1), 'load':(2 - 1)}).rename('id_value') )\n",
    "plotFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this one has 2 lines of conditions for --keep\n",
    "'''\n",
    "%run match_controls_forPlot.py --id ag_base --conditions none -i ag_map_with_alpha.txt --output agp_output.csv -k agp_keep.txt --control agp_control.txt --case=agp_case.txt --nullValues agp_nulls.txt --match agp_match.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this one has 1 line of conditions for --keep\n",
    "'''\n",
    "%run match_controls_forPlot.py --id ag_1 --conditions keep_1L -i ag_map_with_alpha.txt --output agp_output1.csv -k agp_keep_1L.txt --control agp_control.txt --case=agp_case.txt --nullValues agp_nulls.txt --match agp_match.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "base conditions\n",
    "\n",
    "'''\n",
    "\n",
    "%run match_controls_forPlot.py  --id sk_base --conditions none -i sk_hc_merged.txt --nullValues agp_nulls.txt --case skit_case.txt --control skit_control.txt --match skit_match.txt --output sk_output_20.csv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this one has 1 line of conditions for --control and --case\n",
    "\n",
    "this one has a medium range in conditions for --keep\n",
    "--match also has a medium range\n",
    "'''\n",
    "\n",
    "%run match_controls_forPlot.py --id ag_2 --conditions keep_rL -i ag_map_with_alpha.txt --output agp_output2.csv -k agp_keep_rL.txt --control agp_control_1L.txt --case=agp_case_1L.txt --nullValues agp_nulls.txt --match agp_match_rM.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this one has is the base for emp\n",
    "'''\n",
    "%run match_controls_forPlot.py --id emp_base --conditions none -i emp_qiime_mapping_release1.tsv --output emp_output.csv --keep emp_keep.txt  --control emp_control.txt --case  emp_case.txt --match emp_match.txt\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDF = pd.read_csv('data_plot.csv',  sep = '\\t').set_index('id')\n",
    "plotDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plots all the different times to complete each step \n",
    "total time is not included in the plot since it makes the the resolution between other points in the plot\n",
    "'''\n",
    "index_to_symbol = {'ag_base':'b', 'ag_1':'r', 'ag_2':'y', 'emp_base':'g', 'emp_1':'c'\n",
    "                  }\n",
    "\n",
    "for index, row in plotDF.iterrows():\n",
    "    plt.plot(('loud', 'keep', 'case_control', 'null_filter', 'match'), (row['load'], row['keep'], row['case_control'], \n",
    "       row['null_filter'], row['match']), index_to_symbol[index], label = index)\n",
    "    \n",
    "    #plt.plot('total', row['total'], index_to_symbol[index])\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Time (sec)')    \n",
    "plt.xlabel('Stage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe = pd.read_csv('emp_qiime_mapping_release1.tsv', sep='\\t')\n",
    "dataframe\n",
    "Metadata.load( 'emp_qiime_mapping_release1.tsv' ).to_dataframe()['qc_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from before click implemented\n",
    "\n",
    "    if null_values_lines_input == False or match_condition_lines_input == False:\n",
    "        prepped_for_matchMD = case_controlMD\n",
    "    else:\n",
    "        prepped_for_matchMD= filter_prep_for_matchMD(case_controlMD, match_condition_lines_input, null_values_lines_input)\n",
    "\n",
    "    tprepped = time.clock()\n",
    "    print('time to prep Metadata information for match is %s'%(tprepped - tkeep))\n",
    "\n",
    "    if match_condition_lines_input != False:\n",
    "        matchedMD = match_samples( prepped_for_matchMD, match_condition_lines_input )\n",
    "        matchedMD.to_dataframe().to_csv(outputFileName, sep = '\\t')\n",
    "\n",
    "    tmatch = time.clock()\n",
    "    tend = time.clock()\n",
    "    print('time to match is %s'%(tmatch- tprepped))\n",
    "    print('time to do everything %s'%(tend-tstart))\n",
    "\n",
    "    \n",
    "\n",
    "#look in to flag for exclude_query_lines_input\n",
    "if exclude_query_lines_input != False:\n",
    "    afterExclusionMD = keep_samples(originalMD, exclude_query_lines_input)\n",
    "else:\n",
    "    afterExclusionMD = originalMD\n",
    "\n",
    "tkeep = time.clock()\n",
    "print('time to filter out unwanted samples is %s'%(tkeep - tloadedFiles))\n",
    "\n",
    "if case_query_lines_input != False and control_query_lines_input != False:\n",
    "    ids = afterExclusionMD.get_ids()\n",
    "    case_control_Series = pd.Series( ['Unspecified'] * len(ids), ids)\n",
    "    '''\n",
    "    ['Unspecified'] * len(ids) creates a list of elements. The list is the\n",
    "    same length as ids. All the elements are 'Unspecified'\n",
    "    '''\n",
    "    case_control_Series.index.name = afterExclusionMD.id_header\n",
    "    case_controlDF = case_control_Series.to_frame('case_control')\n",
    "    case_control_dict = {'case':case_query_lines_input, 'control':control_query_lines_input }\n",
    "\n",
    "    case_controlMD = determine_cases_and_controls(afterExclusionMD, case_control_dict, case_controlDF)\n",
    "else:\n",
    "    afterExclusionMD.to_dataframe().to_csv(outputFileName, sep = '\\t')\n",
    "    print('keep exit')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correctOutFrame = open('./unitTest_files/%s'%('test_case.txt'),'r').readlines()\n",
    "\n",
    "\n",
    "smallTestFile = pd.DataFrame(index = [1,2,3], data = { 'bmi': ['normal','obese','overweight'], 'age': [23,42,11] } )\n",
    "largeTestFile = pd.read_csv('./unitTest_files/test_data.csv', sep = '\\t' ).set_index('id')\n",
    "truncatedlargeTestFile = pd.read_csv('./unitTest_files/test_data_2.csv', sep = '\\t' ).set_index('id')\n",
    "\n",
    "\n",
    "csvdata_keep = Metadata.load('./unitTest_files/unit_keep.csv').to_dataframe()\n",
    "csvdata_case_control = Metadata.load('./unitTest_files/unit_control.csv').to_dataframe()\n",
    "csvdata_filter = Metadata.load('./unitTest_files/unit_filtered.csv').to_dataframe()\n",
    "csvdata_match = Metadata.load('./unitTest_files/unit_output.csv').to_dataframe()\n",
    "#print(csvdata_match)\n",
    "\n",
    "\n",
    "tstart = time.clock()\n",
    "\n",
    "\n",
    "# reading in commandline arguments\n",
    "all_arguments = sys.argv\n",
    "# selecting all arguments after python file name\n",
    "argumentList = all_arguments[1:]\n",
    "unixOptions = \"i:k:c:e:n:m:o:\"\n",
    "gnuOptions = [\"inputData=\", \"keep=\", \"control=\", \"case=\", \"nullValues=\", \"match=\", \"output=\"]\n",
    "\n",
    "try:\n",
    "    arguments, values = getopt.getopt(argumentList, unixOptions, gnuOptions)\n",
    "except getopt.error as err:\n",
    "    # output error, and return with an error code\n",
    "    print (str(err))\n",
    "    sys.exit(2)\n",
    "\n",
    "\n",
    "#metadata file\n",
    "file_of_metadata = ''\n",
    "user_input_file_name_exclude = ''\n",
    "user_input_file_name_control = ''\n",
    "user_input_file_name_experiment = ''\n",
    "user_input_file_null_values = ''\n",
    "user_input_file_name_match = ''\n",
    "\n",
    "# evaluate given options\n",
    "#print(arguments)\n",
    "\n",
    "for currentArgument, currentValue in arguments:\n",
    "    if currentArgument in (\"-v\", \"--verbose\"):\n",
    "        print (\"enabling verbose mode\")\n",
    "    elif currentArgument in (\"-h\", \"--help\"):\n",
    "        print (\"displaying help\")\n",
    "    elif currentArgument in (\"-i\", \"--inputData\"):\n",
    "        file_of_metadata = currentValue\n",
    "    elif currentArgument in (\"-k\", \"--keep\"):\n",
    "        user_input_file_name_exclude = currentValue\n",
    "    elif currentArgument in (\"-c\", \"--control\"):\n",
    "        user_input_file_name_control = currentValue\n",
    "    elif currentArgument in (\"-e\", \"--case\"):\n",
    "        user_input_file_name_experiment = currentValue\n",
    "    elif currentArgument in (\"-n\", \"--nullValues\"):\n",
    "        user_input_file_null_values = currentValue\n",
    "    elif currentArgument in (\"-m\", \"--match\"):\n",
    "        user_input_file_name_match = currentValue\n",
    "    elif currentArgument in (\"-o\", \"--output\"):\n",
    "        outputFileName = currentValue\n",
    "\n",
    "if file_of_metadata == '':\n",
    "    print('metadata file not found')\n",
    "    sys.exit(2)\n",
    "if outputFileName == '':\n",
    "    print('output put file name not entered')\n",
    "    sys.exit(2)\n",
    "#read metadata file into metadata object\n",
    "originalMD = Metadata.load( file_of_metadata )\n",
    "\n",
    "\n",
    "\n",
    "#each line is a sqlite query to determine what samples to keep\n",
    "exclude_query_lines_input = match_controls.get_user_input_query_lines(user_input_file_name_exclude)\n",
    "#each line is a sqlite query to determine what samples to label control\n",
    "control_query_lines_input = match_controls.get_user_input_query_lines(user_input_file_name_control)\n",
    "#each line is a sqlite query to determine what samples to label case\n",
    "case_query_lines_input = match_controls.get_user_input_query_lines(user_input_file_name_experiment)\n",
    "null_values_lines_input = match_controls.get_user_input_query_lines(user_input_file_null_values)\n",
    "\n",
    "'''\n",
    "each line is tab seperated\n",
    "the first element is the type of match: range or exact\n",
    "    range matches samples if the numerical values compared are with in some other number of eachother\n",
    "        this is only to be used with numerical values\n",
    "    exact matches samples if the values compared are exactly the same\n",
    "        this can be used for strings and numbers\n",
    "the second element is the column to compare values of for the case and control samples\n",
    "the third element is the range number or = (if the match type is exact)\n",
    "    this determines how far away a sample can be from another sample for the given column to be matched\n",
    "'''\n",
    "match_condition_lines_input = match_controls.get_user_input_query_lines(user_input_file_name_match)\n",
    "\n",
    "tloadedFiles = time.clock()\n",
    "print('time to load input files is %s'%(tloadedFiles - tstart))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if test_orderDict() == False:\n",
    "    sys.exit(0)\n",
    "if test_order_keys() == False:\n",
    "    sys.exit(0)\n",
    "if test_stable_marriage() == False:\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if exclude_query_lines_input != False:\n",
    "    afterExclusionMD = match_controls.keep_samples(originalMD, exclude_query_lines_input)\n",
    "else:\n",
    "    afterExclusionMD = originalMD\n",
    "\n",
    "keep = test_keep_samples()\n",
    "print(\"keep_samples function works correctly is %s\"%(keep))\n",
    "\n",
    "tkeep = time.clock()\n",
    "print('time to filter out unwanted samples is %s'%(tkeep - tloadedFiles))\n",
    "\n",
    "if case_query_lines_input != False and control_query_lines_input != False:\n",
    "    ids = afterExclusionMD.get_ids()\n",
    "    case_control_Series = pd.Series( ['Unspecified'] * len(ids), ids)\n",
    "    '''\n",
    "    ['Unspecified'] * len(ids) creates a list of elements. The list is the\n",
    "    same length as ids. All the elements are 'Unspecified'\n",
    "    '''\n",
    "    case_control_Series.index.name = afterExclusionMD.id_header\n",
    "    case_controlDF = case_control_Series.to_frame('case_control')\n",
    "    case_control_dict = {'case':case_query_lines_input, 'control':control_query_lines_input }\n",
    "\n",
    "    case_controlMD = match_controls.determine_cases_and_controls(afterExclusionMD, case_control_dict, case_controlDF)\n",
    "else:\n",
    "    afterExclusionMD.to_dataframe().to_csv(outputFileName, sep = '\\t')\n",
    "    print('keep exit')\n",
    "    sys.exit(0)\n",
    "\n",
    "cas_con = test_determine_cases_and_controls()\n",
    "print(\"determine_cases_and_controls function works correctly is %s\"%(cas_con))\n",
    "\n",
    "if null_values_lines_input == False or match_condition_lines_input == False:\n",
    "    prepped_for_matchMD = case_controlMD\n",
    "else:\n",
    "    prepped_for_matchMD= match_controls.filter_prep_for_matchMD(case_controlMD, match_condition_lines_input, null_values_lines_input)\n",
    "\n",
    "filtered = test_filter_prep_for_matchMD()\n",
    "print(\"filter_prep_for_matchMD function works correctly is %s\"%(filtered))\n",
    "\n",
    "tprepped = time.clock()\n",
    "print('time to prep Metadata information for match is %s'%(tprepped - tkeep))\n",
    "\n",
    "if match_condition_lines_input != False:\n",
    "    matchedMD = match_controls.match_samples( prepped_for_matchMD, match_condition_lines_input )\n",
    "    matchedMD.to_dataframe().to_csv(outputFileName, sep = '\\t')\n",
    "\n",
    "match = test_match_samples()\n",
    "print(\"match_samples function works correctly is %s\"%(match))\n",
    "\n",
    "tmatch = time.clock()\n",
    "tend = time.clock()\n",
    "print('time to match is %s'%(tmatch- tprepped))\n",
    "print('time to do everything %s'%(tend-tstart))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
